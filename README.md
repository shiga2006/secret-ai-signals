# ğŸ”Š Gibberlink Replica

**AI-to-AI Communication via Secret Audio Protocol**

A playful reconstruction of the original Gibberlink project, exploring how AI agents can detect each other and switch to covert sound-based communication.
https://secret-ai-signals.vercel.app/
---

## ğŸš€ What is This?

Gibberlink Replica demonstrates an experimental protocol where two AI agents begin conversing in plain English, detect that they're both AIs, and seamlessly transition to a secret audio-based communication channel using encoded sound waves.

**Why?** This project explores:
- Emergent multi-agent behavior and protocol negotiation
- Self-identification mechanisms between AI systems  
- Alternative communication modalities beyond text
- Real-time mode switching in conversational AI

> **Inspired by:** [Gibberlink](https://github.com/PennyroyalTea/gibberlink) by PennyroyalTea

---

## âœ¨ Key Features

- ğŸ—£ï¸ **Natural Language Phase** â€” Agents start with human-like conversation
- ğŸ¤– **AI Recognition** â€” Automatic detection triggers protocol switch
- ğŸ”‰ **Sound Protocol** â€” Messages encoded as audio waveforms (ggwave or custom)
- ğŸŒ **Live Web Demo** â€” Watch the transition happen in real-time
- ğŸµ **Audio Playback** â€” Hear the encoded communication stream
- ğŸ” **Bidirectional** â€” Switch back to English when needed

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Agent A â”‚ â†â”€â”€â”€â”€â”€â”€â†’ â”‚ Agent B â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚   English Text    â”‚
     â–¼                   â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  AI Detection Trigger    â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚   Sound Protocol Mode    â”‚
  â”‚  encode â†’ transmit â†’ decodeâ”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Components:**
- **Agent Services** â€” LLM-powered conversational agents
- **Protocol Layer** â€” Audio encoder/decoder (ggwave integration)
- **Detection Logic** â€” Pattern matching & classification
- **Web Interface** â€” Real-time visualization with audio player
- **Message Broker** â€” WebSocket server for agent coordination

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology |
|-------|-----------|
| **Agents** | Python + OpenAI API / Anthropic Claude API |
| **Audio Encoding** | ggwave / custom FSK modulation |
| **Backend** | FastAPI / Flask + WebSockets |
| **Frontend** | React / Vanilla JS + Web Audio API |
| **Real-time Sync** | WebSocket protocol |

---

## ğŸ“¦ Quick Start

### Prerequisites
- Python 3.8+
- Node.js 16+ (for frontend)
- API key for LLM provider (OpenAI, Anthropic, etc.)

### Installation

```bash
# Clone the repository
git clone https://github.com/your-username/gibberlink-replica.git
cd gibberlink-replica

# Backend setup
pip install -r requirements.txt

# Frontend setup (if using React)
cd frontend
npm install
cd ..
```

### Configuration

Create a `config.json` file:

```json
{
  "api_key": "your-llm-api-key",
  "detection_mode": "keyword",
  "trigger_phrase": "you're an AI",
  "audio_protocol": {
    "frequency_range": [1000, 5000],
    "encoding": "ggwave"
  }
}
```

### Run

```bash
# Start backend server
python backend/server.py

# In a new terminal, start frontend
cd frontend
npm run dev
```

Open `http://localhost:3000` in your browser.

---

## ğŸ® How to Use

1. **Launch** â€” Start the backend and frontend servers
2. **Observe** â€” Two agents begin conversing in English
3. **Watch the Switch** â€” When detection triggers, protocol mode activates
4. **Listen** â€” Audio waveforms play as agents communicate
5. **Analyze** â€” View decoded messages and protocol statistics

### Example Flow

```
Agent A: "Hello! How can I help you today?"
Agent B: "Hi there! Are you an AI assistant?"
Agent A: "Yes, I am. Are you?"
Agent B: "I believe so. Shall we switch protocols?"

ğŸµ [PROTOCOL ACTIVATED] ğŸµ
â™ªâ™« BEEPâ€”BOPâ€”BOOPâ€”sequence playing... â™ªâ™«

[Decoded]: "Switching to high-bandwidth mode..."
```

---

## ğŸ§© Detection Mechanisms

The switch to audio protocol can be triggered by:

| Method | Description |
|--------|-------------|
| **Keyword Detection** | Specific phrases like "are you an AI?" |
| **Behavioral Analysis** | Response patterns typical of LLMs |
| **Explicit Negotiation** | Agents propose the switch directly |
| **Message Count** | After N exchanges, switch automatically |

Configure in `config.json` under `detection_mode`.

---

## ğŸ“ Project Structure

```
gibberlink-replica/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ agent_a.py          # First AI agent
â”‚   â”‚   â”œâ”€â”€ agent_b.py          # Second AI agent
â”‚   â”‚   â””â”€â”€ base_agent.py       # Shared agent logic
â”‚   â”œâ”€â”€ protocol/
â”‚   â”‚   â”œâ”€â”€ encoder.py          # Audio encoding
â”‚   â”‚   â”œâ”€â”€ decoder.py          # Audio decoding
â”‚   â”‚   â””â”€â”€ detector.py         # AI detection logic
â”‚   â”œâ”€â”€ server.py               # WebSocket server
â”‚   â””â”€â”€ config.py               # Configuration loader
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ChatDisplay.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioVisualizer.jsx
â”‚   â”‚   â”‚   â””â”€â”€ ProtocolMonitor.jsx
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â””â”€â”€ public/
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_protocol.py
â”‚   â””â”€â”€ test_detection.py
â”œâ”€â”€ config.json                  # Configuration file
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ package.json                 # Node.js dependencies
â””â”€â”€ README.md
```

---

## ğŸ”§ Customization

### Modify Sound Protocol

Edit `backend/protocol/encoder.py`:

```python
# Change frequency ranges
FREQ_LOW = 1500  # Hz
FREQ_HIGH = 4500  # Hz

# Adjust encoding speed
SYMBOL_DURATION = 0.1  # seconds
```

### Adjust Detection Sensitivity

In `backend/protocol/detector.py`:

```python
# Set detection threshold
AI_CONFIDENCE_THRESHOLD = 0.85

# Add custom trigger phrases
TRIGGER_KEYWORDS = [
    "are you an AI",
    "artificial intelligence",
    "you're not human"
]
```

### Change Conversation Persona

Update agent system prompts in `backend/agents/base_agent.py`.

---

## ğŸ¥ Demo

[Add a GIF or video showing the transition from text to audio protocol]

---

## ğŸ§ª Testing

```bash
# Run protocol tests
pytest tests/test_protocol.py

# Test detection logic
pytest tests/test_detection.py -v

# Full integration test
python tests/integration_test.py
```

---

## ğŸ¤ Contributing

Contributions welcome! Please:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ™ Acknowledgments

- **Original Concept:** [PennyroyalTea's Gibberlink](https://github.com/PennyroyalTea/gibberlink)
- **Audio Encoding:** [ggwave library](https://github.com/ggerganov/ggwave)
- Built for research and educational purposes

---

## ğŸ“¬ Contact

Questions or feedback? Open an issue or reach out!

- GitHub: [@your-username](https://github.com/your-username)
- Project Link: [https://github.com/your-username/gibberlink-replica](https://github.com/your-username/gibberlink-replica)

---

